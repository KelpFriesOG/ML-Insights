{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0465a895",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks 🧊\n",
    "\n",
    "As dicussed prior, the primary difference between a convolutional neural network (CNN) and a fully connected multi-layer perceptron (MLP) network lies in how the input data is encoded into the network.\n",
    "\n",
    "- MLPs treat input features as independent and flat, losing information about spatial relationships.\n",
    "\n",
    "- **CNNs preserve and exploit the locality of 2D input data**\n",
    " (such as images), enabling the network to learn spatial hierarchies of features.\n",
    "\n",
    "- This is particularly powerful for understanding and preserving the locality of 2D input data (i.e. images).\n",
    "\n",
    "CNNs are basically stacked layers of pattern matching where the process of pattern matching is based on *kernels* which act as trainable weighted sum functions (similar to the role of a perceptron) that sweep in *patches* across the image.\n",
    "\n",
    "- **Each kernel eseentially acts as an eye scanning the image for the presence of a particular feature, based on the parameters of the kernel!**\n",
    "\n",
    "- - The weighted sum computed for each patch generates a feature map associated with that kernel.\n",
    "\n",
    "- - The result of this scanning is a *feature map*: **a spatial map where higher values indicate stronger evidence of the learned pattern in specific regions, and lower (or negative) values indicate absence or contrast of that pattern.**\n",
    "\n",
    "When we last left off we covered how the kernel is applied to each patch, the general movement of a kernel across an image, and intuition behind how kernels can be structured to learn some low level features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad61af",
   "metadata": {},
   "source": [
    "## Understanding Stride and Kernel Movement\n",
    "\n",
    "<img src=\"./media/CNN_visualization.gif\" width=\"500px\">\n",
    "\n",
    "Note how the kernel moves:\n",
    "\n",
    "- Each kernel does not map a completely disjoint patch, each patch has some overlap with the prior and next convolution after it.\n",
    "- The kernel moves or *strides* one pixel at a time and moves to the right and then down. \n",
    "- - Therefore we say that the **stride of this kernel's application is 1**.\n",
    "- If the stride of the kernel was *3* then the kernel's convolutions would produce completely disjoint (non-overlapping) patches but this could result in a kernel potentially going out of bounds of the image **unless we add some padding to the image that prevents this**.\n",
    "\n",
    "**A stride of 1 ensures that the kernel covers the image densely, without skipping positions, and without risking incomplete patches at the edges (assuming appropriate padding is applied).**\n",
    "\n",
    "Assuming square kernels and a square input image we can actually use a formula to compute the dimensions of the feature map produced by the kernel:\n",
    "\n",
    "$$\\text{feature map size} = \\lfloor\\frac{\\text{input size} + 2 \\cdot \\text{padding} - \\text{kernel size}}{\\text{stride}}\\rfloor$$\n",
    "\n",
    "*note the floor operation performed to the fraction*\n",
    "\n",
    "- **The padding here is how many pixels are applied as padding to all sides of the image.**\n",
    "\n",
    "And by size we mean the length or height of the respective item (which should be identical since we assume everything is a square).\n",
    "\n",
    "- **While it may be tempting to rearrange the formula such that it solves for stride, this isn't necessarily helpful.**\n",
    "\n",
    "We could solve for stride as follows:\n",
    "\n",
    "$$\\text{stride} = \\frac{\\text{input size} + 2 \\cdot \\text{padding} - \\text{kernel size}}{\\text{feature map size} - 1}$$\n",
    "\n",
    "- One issue is that sometimes this formula will end up giving you a fractional value for the stride which is not possible since a \"partial pixel\" is not attainable nor useable.\n",
    "\n",
    "Example:\n",
    "\n",
    "Suppose we know all the following and want to calculate stride\n",
    "\n",
    "- Input size = 7\n",
    "- Kernel size = 3\n",
    "- (desired) Output size = 4\n",
    "- Padding = 0\n",
    "\n",
    "$$\\text{stride} = \\frac{7 + 2 \\cdot 0 - 3}{4 - 1} = 1.333$$\n",
    "\n",
    "**There are several potential solutions in this case:**\n",
    "\n",
    "- Add some padding\n",
    "- Change the kernel size\n",
    "- Change the desired output size\n",
    "\n",
    "Or another solution, which is more mathematically involved, would be **transposed convolution** which we will not cover here.\n",
    "\n",
    "When we actually toss data into the models, **kernels in the same level of the neural network (i.e. adjacent kernels) are independent of each other**.\n",
    "\n",
    "- Kernels act on the same underlying input but act as different lenses and filters on the data.\n",
    "- Since they are computed independently, **kernels on the same layer are convoluted in parallel on the same input data.**\n",
    "- This is why GPUs are so useful, they have thousands of tiny computing cores that can be delegated to compute kernels in parallel with a massive amount of data throughput!\n",
    "\n",
    "A **smaller stride (such as 1) maximizes the resolution of the feature map by ensuring that every possible local pattern is examined with significant overlap.** This overlap allows the network to build a detailed and high-resolution representation of the spatial relationships in the image.\n",
    "\n",
    "- In contrast, a larger stride skips positions, reducing overlap and producing a coarser and lower-resolution summary of the input as evident in the smaller feature maps produed as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e32186f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 28, 28])\n",
      "Output shape: torch.Size([1, 6, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "# Code to demonstrate how to create and pass input through a basic Convolution layer in pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "# The number of input channels should be equal to the number of channels in your image i.e. 3 for a RGB patch\n",
    "# The number of output channels is equal to the amount of filters you want to create (in this case I made 6 filters / kernels)\n",
    "convolution = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1)\n",
    "out = convolution(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\\nOutput shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d004d60",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "\n",
    "What if we intentionally wanted to reduce the resolution of an image? What are the ways in which we could do this?\n",
    "\n",
    "- As discussed before, increasing the stride length will substanially reduce the size of the resulting feature map according to the formula:\n",
    "\n",
    "$$\\text{feature map size} = \\lfloor\\frac{\\text{input size} + 2 \\cdot \\text{padding} - \\text{kernel size}}{\\text{stride}}\\rfloor$$\n",
    "\n",
    "In general, **doubling the stride length halves the size of the input feature map, tripling it cuts it to a third of its original size and so on and so forth.**\n",
    "\n",
    "- By creating a smaller feature map, we are *downsampling* our representation of the original image.\n",
    "\n",
    "- Intentionally downsampling is good practice to generalize our insights from the input data while also improving the performance of the model (which comes as result of needing to compute smaller feature maps).\n",
    "\n",
    "Another option is to use a technique called *pooling* which is a form of postprocessing on the feature-map itself somewhat similar to convolution.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "<img src=\"./media/convolution_and_max_pooling_example.png\" width=\"500px\">\n",
    "\n",
    "In the example, the kernel is:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 1 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "1 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Max pooling is a technique which groups up different patches of the feature map and chooses the highest value on that patch to represent the entire patch.**\n",
    "\n",
    "- Max pooling can be thought of as a technique similar to convolution. The example shows how the max pooling process was done \"with a 2x2 filter and a stride of 2\". But you could reinterprate that as simply chunking up the feature map into 2 by 2 patches and then reducing each 2 by 2 patch to its greatest value.\n",
    "\n",
    "- Alternatively we could apply **average pooling** to reduce each patch into the average of it's values. Note that this value is not supposed to directly represent a pixel, therefore it is perfectly okay for it to be fractional.\n",
    "\n",
    "The biggest downside of this technique is that unlike general convolution, it is an application of a fixed rule as opposed to a tuneable function.\n",
    "\n",
    "- Strided convolution (stride > 1) generates a new learned feature map while simultaneously reducing spatial resolution which integrates downsampling with feature extraction, unlike pooling which applies a fixed post-processing rule.\n",
    "\n",
    "- Pooling can still serve as a supplementary technique, applied after standard or strided convolution, to further reduce spatial size or introduce robustness to local variations\n",
    "\n",
    "**Ultimately you can think of pooling as a sort of plug and play post processing tweak that may slightly improve the model, whereas strided convolution generates different insights in the original feature map altogether.**\n",
    "\n",
    "**Note that if you do choose to apply pooling, you can tweak the stride length of the pooling process to be greater than size of the filter to skip portions of the feature map entirely, or choose stride lengths smaller than the size of the filter to perform overlapping pooling.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc24273",
   "metadata": {},
   "source": [
    "## Adding Channels and Activations\n",
    "\n",
    "So far we have been discussing kernels as a 2d 3x3 matrix, but in reality there is a third dimension that must be accounted for in the case of images with multiple channels.\n",
    "\n",
    "- Most images have 3 or 4 channels: red, green, blue, and optionally alpha (transparency).\n",
    "\n",
    "- In the context of deep learning, we can view the kernel as a 3 dimensional cube, where each slice of the cube is applied to each channel / slice of the input image.\n",
    "\n",
    "**In the context of deep learning and libraries like Tensorflow, this kernel is an example of a tensor.**\n",
    "\n",
    "- Simply put, **a tensor is a multidimensional data structure with semantical rules that allow it perform within linear algebra calculations and operations like dot products and matrix multiplications.**\n",
    "\n",
    "- A 3d array such as a kernel is a rank-3 tensor.\n",
    "\n",
    "However, when we apply the kernel 3 by 3 by 3 kernel to a 3 by 3 by 3 image patch, our resulting feature is a singular number.\n",
    "\n",
    "---\n",
    "\n",
    "### Example of kernel application with 3 channels\n",
    "\n",
    "Input patches:\n",
    "\n",
    "$$\n",
    "\\text{patch}_R =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 1 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "2 & 1 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{patch}_G =\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "1 & 2 & 1 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{patch}_B =\n",
    "\\begin{bmatrix}\n",
    "2 & 0 & 2 \\\\\n",
    "1 & 1 & 1 \\\\\n",
    "2 & 0 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Kernel weights:\n",
    "\n",
    "$$\n",
    "\\text{kernel}_R =\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "1 & -1 & 1 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{kernel}_G =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 1 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "1 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{kernel}_B =\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & -1 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "-1 & 0 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Dot product results:\n",
    "\n",
    "$$\n",
    "\\text{R sum: } (1\\times 0) + (2\\times 1) + (1\\times 0) + (0\\times 1) + (1\\times -1) + (0\\times 1) + (2\\times 0) + (1\\times 1) + (2\\times 0) = 2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{G sum: } (0\\times 1) + (1\\times 0) + (0\\times 1) + (1\\times 0) + (2\\times 1) + (1\\times 0) + (0\\times 1) + (1\\times 0) + (0\\times 1) = 2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{B sum: } (2\\times -1) + (0\\times 0) + (2\\times -1) + (1\\times 0) + (1\\times 1) + (1\\times 0) + (2\\times -1) + (0\\times 0) + (2\\times -1) = -7\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Final value:\n",
    "\n",
    "$$\n",
    "\\text{output feature} = 2 + 2 + (-7) = -3\n",
    "$$\n",
    "\n",
    "**The idea that a kernel \"squashes\" all the color channel info at each patch into a single scalar feels like it might lose richness.**\n",
    "\n",
    "- The kernel’s job is precisely to blend and weigh the input channels in a way that highlights useful patterns.\n",
    "\n",
    "- A kernel might learn to detect red-green contrasts\n",
    "\n",
    "- Another kernel might learn to detect blue intensity edges\n",
    "\n",
    "- **The dot product produces 1 value that reflects the combined evidence across all channels for that kernel's target feature.**\n",
    "\n",
    "---\n",
    "\n",
    "## The Missing Piece: Achieving Nonlinearity\n",
    "\n",
    "Recall that we showed how simple weighted sums failed to capture non-linear relationships in basic feed forward networks. **Ultimately, by computing dot products to make feature maps, we are creating the same weighted sums and have to tackle the same problem.**\n",
    "\n",
    "If we consider the individual computed features in a feature map to be akin to the scalar outputs of neurons in a basic perceptron network, we can postprocess each feature by applying an activation function like ReLU to it.\n",
    "\n",
    "ReLU is simply defined as:\n",
    "\n",
    "$$\n",
    "\\operatorname{ReLU}(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "This means:\n",
    "- If the input value is positive, ReLU leaves it unchanged.\n",
    "- If the input value is negative, ReLU sets it to zero.\n",
    "\n",
    "Without ReLU:\n",
    "- The network would just compute **linear combinations** of the input features at every layer.\n",
    "- Stacking multiple layers would still result in a model that is no more powerful than a single linear layer.\n",
    "- The network would be unable to learn or represent the non-linear patterns that are crucial for complex tasks like image classification.\n",
    "\n",
    "With ReLU:\n",
    "- We introduce non-linearity at each layer, allowing the network to model complex decision boundaries.\n",
    "- We create **sparse activations** — many outputs are zero, which makes the network more efficient and helps reduce overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### Example of ReLU\n",
    "\n",
    "Suppose a convolution produces a small feature map:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "-3 & 5 \\\\\n",
    "2 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Applying ReLU:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 5 \\\\\n",
    "2 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- This is ideal because our goal is to specialize each feature or \"neuron\" in the feature map to detect the likelihood of the kernel's feature being present at a given location.\n",
    "\n",
    "- **Understand the nuance:** having negative values in the kernel itself is important because these allow the kernel to capture contrasts and patterns (for example, differences between light and dark regions) that define the feature it is looking for. \n",
    "\n",
    "However, having negative values in the **feature map** is unnecessary, because the role of the feature map is to indicate the *presence* of a feature at a location, not the absence of one. ReLU ensures that only positive evidence for a feature is propagated forward.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86a38782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Convolution\n",
      "Input shape: torch.Size([1, 1, 8, 8])\n",
      "Output shape: torch.Size([1, 1, 4, 4])\n",
      "Caught error: Calculated padded input size per channel: (2 x 2). Kernel size: (3 x 3). Kernel size can't be greater than actual input size\n",
      "Edge case: No errors, output shape: torch.Size([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Below are example of valid and invalid convolutions based on the combination of strides, kernel size, and input \"image\" size.\n",
    "\n",
    "# 1) VALID Convolution\n",
    "\n",
    "input_1 = torch.randn(1, 1, 8, 8) # A single \"image\" with one channel and 8 by 8 dimensions\n",
    "conv_good = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=2, padding=1)\n",
    "out_good = conv_good(input_1)\n",
    "\n",
    "print(f\"Valid Convolution\\nInput shape: {input_1.shape}\\nOutput shape: {out_good.shape}\")\n",
    "\n",
    "# 2) Invalid Convolution (kernel larger than input image)\n",
    "\n",
    "input_2 = torch.randn(1, 1, 2, 2) # A single \"image\" with one channel and 2 by 2 dimensions\n",
    "conv_bad = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0) # Our kernel is larger than the image. Oh boy.\n",
    "\n",
    "try:\n",
    "    out_bad = conv_bad(input_2)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Caught error: {e}\")\n",
    "    \n",
    "# 3) Edge case: Valid Convolution (stride causes feature map to shrink to a single 1x1)\n",
    "\n",
    "input_3 = torch.randn(1, 1, 5, 5)\n",
    "conv_large_stride = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=4, padding=0) \n",
    "# The stride here will take the initial patch and immeadiately shift it out of the image which is only 5 pixels wide!\n",
    "# But this does not happen! Instead the convolution just stays in place, realizing the any shift in any direction with the magnitude of\n",
    "# the stride will result in it going out of bounds.\n",
    "\n",
    "try:\n",
    "    out_bad = conv_large_stride(input_3)\n",
    "    # The result is a feature map which is a single feature!\n",
    "    print(f\"Edge case: No errors, output shape: {out_bad.shape}\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Caught error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d08745c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 8, 8])\n",
      "Convolution output shape: torch.Size([1, 2, 4, 4])\n",
      "Post-pooling shape: torch.Size([1, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# An example that shows how to achieve effective max pooling in pytorch\n",
    "\n",
    "# 1) Valid Pooling\n",
    "\n",
    "input_1 = torch.randn(1, 1, 8, 8) # A single \"image\" with one channel and 8 by 8 dimensions\n",
    "conv_good = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=2, padding=1)\n",
    "out_good = conv_good(input_1)\n",
    "\n",
    "# Then we can use the output from the convolution as an input to a max pooling layer\n",
    "max_pool_good = nn.MaxPool2d(kernel_size=2, stride=2) # Standard 2 by 2 pooling filter with stride = 2 to create non-overlapping but fully covering regions.\n",
    "pool_out_good = max_pool_good(out_good)\n",
    "\n",
    "print(f\"Input shape: {input_1.shape}\\nConvolution output shape: {out_good.shape}\\nPost-pooling shape: {pool_out_good.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb9cf9",
   "metadata": {},
   "source": [
    "## Putting it Together\n",
    "\n",
    "Recall one of the questions mentioned in the teaser in the prior lesson:\n",
    "\n",
    "*\"Even if we can detect low-level features, how exactly are these combined to represent more abstract patterns or objects?\"*\n",
    "\n",
    "What we've discussed so far is only how to extract the first level of features from an image.\n",
    "\n",
    "The process of getting higher-level features involves adding two simple steps to our current recipe:\n",
    "\n",
    "1) **Input raw image**: e.g., a 3-channel RGB image of size 32×32. Shape is $= (32, 32, 3)$\n",
    "\n",
    "2) **Run the kernels over the image**: Each kernel (with depth matching the input channels) slides over the image, producing a 2D feature map. Each map highlights regions where its learned pattern (e.g., edge, texture, color contrast) is detected.\n",
    "\n",
    "3) **Apply an activation function to each feature in each kernel**: Preferably ReLU or a variant of it.\n",
    "\n",
    "4) **Stack the 2D feature maps generated by each kernel**: If we used 6 kernels this forms a stack of 6 feature maps. Together, these can be thought of as a new multi-channel \"image\" of shape $(H, W, 6)$ (note that the input image had 3 channels).\n",
    "\n",
    "5) **Treat this new stacked entity as the new \"image\" and repeat steps 2-5**:\n",
    "   - The next layer applies new kernels that operate across *all* of these input channels.\n",
    "   - Each kernel now learns to detect patterns *of patterns* — e.g., combinations of edges forming corners, simple textures forming shapes.\n",
    "   - The output of these kernels is again a stack of 2D feature maps.\n",
    "\n",
    "**By stacking simple patterns in place of the original image, deeper layers of the CNN work on tuning to increasingly more complex patterns:**\n",
    "\n",
    "- **First layer:** Detects low-level features like edges, lines, simple color contrasts.\n",
    "- **Second layer:** Detects combinations of these — corners, curves, small shapes.\n",
    "- **Third layer (and beyond):** Detects parts of objects, textures, or entire patterns relevant to the task (e.g., eyes, wheels, fur texture).\n",
    "\n",
    "In this way, the network builds a hierarchy: simple features are combined into complex ones, layer by layer, until we have high-level abstractions that can be used for tasks like classification or detection.\n",
    "\n",
    "**An important caveat is that these features are learned, not preprogrammed. This means that developers do not create the kernels themselves.**\n",
    "\n",
    "- Instead: the kernels start out with random values (weights). \n",
    "- Through training, the network adjusts these values using optimization techniques (like gradient descent) to minimize a loss function, only \"learning\" what patterns are useful for the task (e.g., classification).\n",
    "- Each kernel will find and converge to different minimums which reflect distinct features!\n",
    "- This process allows the network to discover the most relevant features directly from the data, rather than relying on human-designed rules or filters.\n",
    "\n",
    "After we generalize to some high level features, what's next?\n",
    "\n",
    "<img src=\"./media/feature_learning_what_next.png\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87133cb3",
   "metadata": {},
   "source": [
    "## Classification: Interpreting High Level Features\n",
    "\n",
    "After we generate the high level features as part of the feature learning process we have yet to accomplish our end goal: classification.\n",
    "\n",
    "- We want to know if a particular concept (ex. car, dog, airplane, e.t.c) is a subject of the image (in other words we want to deduce the likelihood of potential subjects).\n",
    "\n",
    "To understand how to do this we can take a look at our prior MNIST model for some guidance:\n",
    "\n",
    "```python\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "```\n",
    "\n",
    "That's right, after all is said and done, we still need to take the features generated by the last layer of our feature learning pipeline and flatten it to fit into a fully connected linear layer!\n",
    "\n",
    "### Example:\n",
    "\n",
    "We’ve extracted, say, 16 maps of size 7×7. To treat these as inputs to a standard dense layer, we first flatten each 16 by 16 by 7 tensor into a single 1-D vector of length $16 \\cdot 7 \\cdot 7 = 784$.\n",
    "\n",
    "- **This singular flattened tensor will encode the presence of each feature in each feature map as a linear array.**\n",
    "\n",
    "- We take that 784-dim vector and **pass it through a dense layer** (or two)… just like in our MNIST example.\n",
    "\n",
    "You should ask yourself: Doesn't flattening contradict the benefits of the feature extraction pipeline (preserving locality while extracting insights on the data)?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "<p>\n",
    "    By the time we flatten, we’ve already encoded the important local relationships into our feature values.\n",
    "</p>\n",
    "<ul>\n",
    "    <li>Early layers detect local patterns (edges, corners) in specific neighborhoods.</li>\n",
    "    <li>Deeper layers combine those into more abstract motifs (textures, parts of objects).\n",
    "    When you look at a single activation in your final feature-map stack, it’s already a summary of “what was going on” in a small receptive field of the image. Flattening just lines up those summaries into a vector.</li>\n",
    "    <li>The goal of the dense layers is to now understand which of the distilled features are predictive of each class. Dense layers only need to learn which features matter, not where they were. Classification usually doesn’t care if an edge-detector fired at the top-left or bottom-right of its receptive field—just that it fired strongly somewhere.</li>\n",
    "    <li>After sufficent convolution and pooling, you only care about presence and strength of features, not their exact grid coordinates.</li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "**Here is an example of what an adaptive classifier could look like in order to process the outputted feature maps from the feature learning process:**\n",
    "\n",
    "```python\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_feats, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        # num_feats = num_filters * H_out * W_out\n",
    "        self.fc1 = nn.Linear(num_feats, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)     # flatten\n",
    "        x = self.relu(self.fc1(x))    # hidden layer\n",
    "        x = self.fc2(x)               # logits\n",
    "        return x\n",
    "\n",
    "```\n",
    "\n",
    "Lastly the only issue remains that the output of this fully connected layer will not give us probabilties, instead it will give use an unbounded and unpredictable range of values which need to normalized to convert into probabilities.\n",
    "\n",
    "### Normalizing via Softmax\n",
    "\n",
    "In the code for my MNIST demo you will see the following line:\n",
    "\n",
    "```python\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "```\n",
    "\n",
    "While we have glossed over logits and loss functions before, it may be benefical to recap these topics to understand what this line is doing!\n",
    "\n",
    "As we discussed in very early lessons, logits are the unnormalized scores output by the final dense layer of our network. They can be any real number, positive or negative, and they don’t need to sum to 1. In our MNIST example, for each image the model outputs a vector of 10 logits, one per digit class (0–9).\n",
    "\n",
    "Instead of normalizing these values with a **softmax function** before feeding them to the loss function, we simply set the flag *\"from_logits = true\"* to let the `keras` API deal with that conversion before calculating the loss function.\n",
    "\n",
    "The **softmax function looks intimidating but is trivial to compute**:\n",
    "\n",
    "$$\\operatorname{P}(y = i | z) = \\operatorname{softmax}(z)_i = \\frac{e^{z_i}}{\\Sigma_{j=1}^{K}e^{z_i}}$$\n",
    "\n",
    "Lets understand it through an example:\n",
    "\n",
    "Given the logits $3, 1, 0.2$:\n",
    "\n",
    "**Given logits** \\((3, 1, 0.2)\\):\n",
    "\n",
    "1. **Exponentiate**  \n",
    "   $$\n",
    "     \\exp(3)=20.09,\\quad \\exp(1)=2.72,\\quad \\exp(0.2)=1.22\n",
    "   $$\n",
    "\n",
    "    - Note that $\\exp(x) = e^x$\n",
    "\n",
    "2. **Compute sum of exponentials**  \n",
    "   $$\n",
    "     20.09 + 2.72 + 1.22 = 24.03\n",
    "   $$\n",
    "\n",
    "3. **Compute softmax**  \n",
    "   $$\n",
    "   \\operatorname{softmax}(z)\n",
    "   = \\bigl[\\,20.09/24.03,\\;2.72/24.03,\\;1.22/24.03\\bigr]\n",
    "   \\approx [0.84,\\;0.11,\\;0.05]\n",
    "   $$\n",
    "\n",
    "- All outputs sum to 1.  \n",
    "- Negative logits work the same: $\\exp(\\text{negative})$ yields a small positive number.  \n",
    "\n",
    "---\n",
    "\n",
    "**Numerical‐stability trick (shift‐invariance):**  \n",
    "Before exponentiating, subtract the maximum logit to avoid overflow (you should do this if you see that some logits are particularly large to avoid overflow when computing large exponentials)\n",
    "\n",
    "> $$\n",
    "> \\tilde z_i = z_i - \\max_j z_j,\\qquad\n",
    "> \\operatorname{softmax}(z)_i\n",
    "> = \\frac{\\exp(\\tilde z_i)}{\\sum_k \\exp(\\tilde z_k)}.\n",
    "> $$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "218fe364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelpfries/miniconda3/envs/ml_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8928 - loss: 0.3665 - val_accuracy: 0.9818 - val_loss: 0.0553\n",
      "Epoch 2/5\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0513 - val_accuracy: 0.9880 - val_loss: 0.0398\n",
      "Epoch 3/5\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0314 - val_accuracy: 0.9898 - val_loss: 0.0347\n",
      "Epoch 4/5\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0238 - val_accuracy: 0.9910 - val_loss: 0.0327\n",
      "Epoch 5/5\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0186 - val_accuracy: 0.9917 - val_loss: 0.0327\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9875 - loss: 0.0404\n",
      "\n",
      "Test accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "# Quick Tensorflow / Keras code to train an MNIST model using a basic CNN model\n",
    "# After testing other variants of the implementation you should find this one to\n",
    "# be both the most quick and intuitive and speedy implementation in terms of compile\n",
    "# (with pytorch being a close second)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "def keras_training_process():\n",
    "    # 1. Load & preprocess MNIST\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.0  # normalize to [0,1]\n",
    "    x_test  = x_test.astype(\"float32\")  / 255.0\n",
    "\n",
    "    # Add channel dimension: (batch, 28,28) → (batch,28,28,1)\n",
    "    x_train = x_train[..., None]\n",
    "    x_test  = x_test[..., None]\n",
    "\n",
    "    # 2. Build the model\n",
    "    model = keras.Sequential([\n",
    "        # --- Feature extraction ---\n",
    "        layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\",\n",
    "                    input_shape=(28,28,1)),\n",
    "        # output: (batch,28,28,32)\n",
    "        \n",
    "        layers.MaxPool2D(pool_size=2, strides=2),\n",
    "        # output: (batch,14,14,32)\n",
    "        \n",
    "        layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "        # output: (batch,14,14,64)\n",
    "        \n",
    "        layers.MaxPool2D(pool_size=2, strides=2),\n",
    "        # output: (batch,7,7,64)\n",
    "        \n",
    "        # --- Classification head ---\n",
    "        layers.Flatten(),                    # → (batch, 7*7*64 = 3136)\n",
    "        layers.Dense(128, activation=\"relu\"), \n",
    "        # hidden dense layer learns combinations of the 3136 features\n",
    "        \n",
    "        layers.Dense(10)                     # logits for 10 classes\n",
    "        # no softmax here: we’ll use from_logits=True in the loss\n",
    "    ])\n",
    "\n",
    "    # 3. Compile with a logits‐aware loss\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # 4. Train\n",
    "    model.fit(x_train, y_train,\n",
    "            validation_split=0.1,  # hold out 10% of train set for val\n",
    "            batch_size=64,\n",
    "            epochs=5)\n",
    "\n",
    "    # 5. Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=64)\n",
    "    print(f\"\\nTest accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "keras_training_process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d2340fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: GPU\n",
      "Epoch 1/20 — Loss: 0.1822\n",
      "Epoch 2/20 — Loss: 0.0769\n",
      "Epoch 3/20 — Loss: 0.0640\n",
      "Epoch 4/20 — Loss: 0.0576\n",
      "Early stopping: 3 epochs below 0.08.\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# More manual and tuneable MNIST training loop with Tensorflow / Keras\n",
    "# Note that I will include a pure tensorflow version without the use of the Keras API,\n",
    "# but this is no longer the standard way of developing production grade code.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def keras_custom_training():\n",
    "    # Check for GPU\n",
    "    device = \"GPU\" if tf.config.list_physical_devices('GPU') else \"CPU\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 1e-4   # L2 regularization\n",
    "    n_epochs = 20         # Maximum epochs\n",
    "    batch_size = 64\n",
    "    target_loss = 0.08    # Early stopping threshold\n",
    "    patience = 3          # Consecutive epochs below threshold\n",
    "\n",
    "    # Load and preprocess MNIST\n",
    "    (x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_train = x_train[..., None]  # (batch, 28, 28, 1)\n",
    "    y_train = y_train.astype(\"int32\")\n",
    "\n",
    "    # Create dataset\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_ds = train_ds.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "    # Build CNN model manually using Functional API\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\",\n",
    "                            kernel_regularizer=keras.regularizers.l2(weight_decay))(inputs)\n",
    "    x = keras.layers.MaxPool2D(2, 2)(x)  # -> 14x14x32\n",
    "    x = keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\",\n",
    "                            kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
    "    x = keras.layers.MaxPool2D(2, 2)(x)  # -> 7x7x64\n",
    "    x = keras.layers.Flatten()(x)        # -> 3136\n",
    "    x = keras.layers.Dense(128, activation=\"relu\",\n",
    "                        kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
    "    outputs = keras.layers.Dense(10)(x)  # logits\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # Custom training loop\n",
    "    loss_history = []\n",
    "    consec_below = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        batches = 0\n",
    "        for batch_x, batch_y in train_ds:\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(batch_x, training=True)\n",
    "                loss = loss_fn(batch_y, logits)\n",
    "                # Add L2 losses\n",
    "                loss += sum(model.losses)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            epoch_loss += loss.numpy()\n",
    "            batches += 1\n",
    "\n",
    "        avg_loss = epoch_loss / batches\n",
    "        loss_history.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} — Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_loss < target_loss:\n",
    "            consec_below += 1\n",
    "            if consec_below >= patience:\n",
    "                print(f\"Early stopping: {patience} epochs below {target_loss}.\")\n",
    "                break\n",
    "        else:\n",
    "            consec_below = 0\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    # Plot loss curve\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(loss_history, marker='o')\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Average Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "keras_custom_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d8eb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: GPU\n",
      "Epoch 1/20 — Loss: 0.1740\n",
      "Epoch 2/20 — Loss: 0.0654\n",
      "Epoch 3/20 — Loss: 0.0526\n",
      "Epoch 4/20 — Loss: 0.0474\n",
      "Early stopping: 3 epochs below 0.08.\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 13:32:22.441048: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pure Tensorflow CNN training loop (not recommended but you can try it)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tensorflow_training_loop():\n",
    "    # 1. Check for GPU\n",
    "    device = \"GPU\" if tf.config.list_physical_devices('GPU') else \"CPU\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 2. Hyperparameters\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 1e-4  # L2 regularization factor\n",
    "    n_epochs = 20        # Maximum epochs\n",
    "    batch_size = 64\n",
    "    target_loss = 0.08   # Early stopping threshold\n",
    "    patience = 3         # Consecutive epochs below threshold\n",
    "\n",
    "    # 3. Load & preprocess MNIST (using tf.keras.datasets for convenience)\n",
    "    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_train = np.expand_dims(x_train, axis=-1)  # (batch, 28, 28, 1)\n",
    "    y_train = y_train.astype(\"int32\")\n",
    "\n",
    "    train_ds = (tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "                .shuffle(buffer_size=1024)\n",
    "                .batch(batch_size))\n",
    "\n",
    "    # 4. Define model weights and biases manually\n",
    "    initializer = tf.initializers.GlorotUniform()\n",
    "    # Conv1: 3x3 kernel, 1->32 channels\n",
    "    W1 = tf.Variable(initializer(shape=[3, 3, 1, 32]), name=\"W1\")\n",
    "    b1 = tf.Variable(tf.zeros([32]), name=\"b1\")\n",
    "    # Conv2: 3x3 kernel, 32->64 channels\n",
    "    W2 = tf.Variable(initializer(shape=[3, 3, 32, 64]), name=\"W2\")\n",
    "    b2 = tf.Variable(tf.zeros([64]), name=\"b2\")\n",
    "    # Dense1: flatten 7*7*64 -> 128\n",
    "    W3 = tf.Variable(initializer(shape=[7*7*64, 128]), name=\"W3\")\n",
    "    b3 = tf.Variable(tf.zeros([128]), name=\"b3\")\n",
    "    # Dense2: 128 -> 10 logits\n",
    "    W4 = tf.Variable(initializer(shape=[128, 10]), name=\"W4\")\n",
    "    b4 = tf.Variable(tf.zeros([10]), name=\"b4\")\n",
    "\n",
    "    # 5. Model forward function\n",
    "    def model(x):\n",
    "        # Conv1 + ReLU + MaxPool\n",
    "        x = tf.nn.conv2d(x, W1, strides=1, padding=\"SAME\") + b1\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding=\"SAME\")  # -> 14x14x32\n",
    "        # Conv2 + ReLU + MaxPool\n",
    "        x = tf.nn.conv2d(x, W2, strides=1, padding=\"SAME\") + b2\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding=\"SAME\")  # -> 7x7x64\n",
    "        # Flatten\n",
    "        x = tf.reshape(x, [-1, 7*7*64])\n",
    "        # Dense1 + ReLU\n",
    "        x = tf.matmul(x, W3) + b3\n",
    "        x = tf.nn.relu(x)\n",
    "        # Dense2 (logits)\n",
    "        logits = tf.matmul(x, W4) + b4\n",
    "        return logits\n",
    "\n",
    "    # 6. Loss function and optimizer\n",
    "    loss_fn = lambda labels, logits: tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    ) + weight_decay * tf.add_n([tf.nn.l2_loss(v) for v in [W1, W2, W3, W4]])\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # 7. Custom training loop with early stopping\n",
    "    loss_history = []\n",
    "    consec_below = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for batch_x, batch_y in train_ds:\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(batch_x)\n",
    "                loss = loss_fn(batch_y, logits)\n",
    "            grads = tape.gradient(loss, [W1, b1, W2, b2, W3, b3, W4, b4])\n",
    "            optimizer.apply_gradients(zip(grads, [W1, b1, W2, b2, W3, b3, W4, b4]))\n",
    "            epoch_loss += loss.numpy()\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        loss_history.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} — Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if avg_loss < target_loss:\n",
    "            consec_below += 1\n",
    "            if consec_below >= patience:\n",
    "                print(f\"Early stopping: {patience} epochs below {target_loss}.\")\n",
    "                break\n",
    "        else:\n",
    "            consec_below = 0\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    # 8. Plot loss curve\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(loss_history, marker='o')\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Average Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "tensorflow_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "881fd67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/20 — Loss: 0.1747\n",
      "Epoch 2/20 — Loss: 0.0527\n",
      "Epoch 3/20 — Loss: 0.0384\n",
      "Epoch 4/20 — Loss: 0.0301\n",
      "Early stopping: 3 epochs below 0.08.\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Research grade simple CNN code using Pytorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Hyperparameters\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4   # L2 regularization\n",
    "n_epochs = 20         # Maximum epochs\n",
    "batch_size = 64\n",
    "target_loss = 0.08    # Early stopping threshold\n",
    "patience = 3          # Consecutive epochs below threshold\n",
    "\n",
    "# 3. Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),               # Convert to tensor (C,H,W) with values [0,1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 4. Define CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # -> 14x14\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # -> 7x7\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        logits = self.fc2(x)\n",
    "        return logits\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# 5. Loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()  # includes softmax internally\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# 6. Custom training loop with early stopping\n",
    "loss_history = []\n",
    "consec_below = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch_x)\n",
    "        loss = loss_fn(logits, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} — Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    if avg_loss < target_loss:\n",
    "        consec_below += 1\n",
    "        if consec_below >= patience:\n",
    "            print(f\"Early stopping: {patience} epochs below {target_loss}.\")\n",
    "            break\n",
    "    else:\n",
    "        consec_below = 0\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# 7. Plot loss curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(loss_history, marker='o')\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1523a549",
   "metadata": {},
   "source": [
    "# Additional Optimizations\n",
    "\n",
    "Now that we're accustomed to the traditional CNN pipeline, we have scratched the surface of an iceberg of techniques that modern CNNs use in practice.\n",
    "\n",
    "- While the fundamental idea and general structure of CNNs is consistent throughout most approaches, several optimizations can be made in any stage of the training loop.\n",
    "\n",
    "Some of these techniques include:\n",
    "\n",
    "- **Dropout Layers**: Randomly zero out some features in a feature map to prevent overfitting\n",
    "- **Batch Normalization**: Use the statistical mean and variance across a batch of inputs to normalize the outputs in a feature map before applying ReLU.\n",
    "- **Data Augmentation**: Apply random transformations to input images such as cropping, flipping, or color filters, to ensure that the network learns the concept without relying or being biased in determining classes based on the location or color of features.\n",
    "- **Global Pooling**: Instead of feeding sequential flattened feature maps for classification, we could apply one last pooling layer beforehand to generate a singular value per feature and use those for classification.\n",
    "- **Skip Connections**: We can use a parameter to allow the output from one layer to skip some of the next layers and feed directly as the input for these deeper layers.\n",
    "\n",
    "---\n",
    "\n",
    "## Dropout Layers\n",
    "\n",
    "The intuition behind using dropout layers is that we seek to randomly zero out the presence of some features in a feature map.\n",
    "\n",
    "- Dropout layers act as another form of regularization because they offer a tradeoff between bias and variance similar to L1 and L2 regularization.\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$y = W * x$$\n",
    "\n",
    "is the typical weighted sum that describes the main operation conducted prior to applying non-linearity.\n",
    "\n",
    "We can apply a mask to the inputs as follows:\n",
    "\n",
    "$$y=W⋅(M⊙x)$$\n",
    "\n",
    "Where $M$ is a mask and $⊙$ is elementwise multiplication.\n",
    "\n",
    "These layers can be thought of as a mask on top of the inputted feature maps that is applied prior to calculating the activation of the layer.\n",
    "We do not want to apply this technique directly to image data because that would corrupt the actual data in the image itself, **but applying it between convolutional layers or even between fully connected layers that work with the feature maps (not the image data) can be beneficial.**\n",
    "\n",
    "Dropout layers are used to address and prevent the problem of **overfitting** (prevent the model from \"memorizing\" the data):\n",
    "\n",
    "- Because downsampling techniques like **strided convolution and pooling already address many overfitting concerns, dropout is rarely applied in the convolutional stack** in modern models.\n",
    "\n",
    "- Instead, dropout layers are more frequently used between fully connected layers since that portion of a CNN is more prone to overfitting without them.\n",
    "\n",
    "- Each time we pass a training image or batch of images, we are slightly tweaking the network by randomly selecting what neurons to drop.\n",
    "\n",
    "- - In essence we are **training slightly different networks with each forward pass**, and we take one simple step at the end to average out the results of training across them.\n",
    "\n",
    "**Dropout layers can be added between convolutional layers, but are more often used in the classification pipeline, between fully connected dense layers.**\n",
    "\n",
    "The impact of dropout’s random deactivations is automatically compensated for, so that at test time no further adjustments are needed.\n",
    "\n",
    "- If some fraction, **$p$, of the activations are zeroed out randomly in each forward TRAINING pass**, we have to scale up the remaining activations to keep the expected output value in a consistent range.\n",
    "\n",
    "- **The remaining activations are scaled up by $\\frac{1}{1 - p}$**\n",
    "\n",
    "**During testing, dropout is deactivated, meaning no neurons are dropped**.\n",
    "\n",
    "- The scaling that happened during training ensures that the outputs are already calibrated. This means no need for further adjustment at test time.\n",
    "\n",
    "In modern frameworks like Pytorch and Tensorflow, the **dropout layers automatically behave differently under training and testing environments.**\n",
    "\n",
    "For example:\n",
    "\n",
    "Suppose $p = 25\\%$, meaning 25% of the neurons are deactivated in a dropout layer during training.\n",
    "\n",
    "- During training, the dropout layer will apply this multiplier to the remaining living neurons: $\\frac{1}{(1 - 0.25)}$\n",
    "- This scale up ensures that the magnitude of the activations remains consistent during training and testing (during which no neurons are deactivated).\n",
    "\n",
    "---\n",
    "\n",
    "**In convolutional layers, applying dropout means zeroing out entire channels (feature maps), not individual neurons within a map.**\n",
    "\n",
    "- This is sometimes called **spatial dropout or Dropout2d**.\n",
    "\n",
    "- Zeroing out entire channels **does not affect dimensionality: the input retains the same number of channels, but some contain only zeros during that pass**.\n",
    "\n",
    "- For example, if the input has 16 channels, **we randomly select entire feature maps to zero out, not individual features within them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98fbcbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNWithDropout                           [16, 10]                  --\n",
       "├─Conv2d: 1-1                            [16, 32, 32, 32]          896\n",
       "├─Conv2d: 1-2                            [16, 64, 32, 32]          18,496\n",
       "├─MaxPool2d: 1-3                         [16, 64, 16, 16]          --\n",
       "├─Dropout2d: 1-4                         [16, 64, 16, 16]          --\n",
       "├─Linear: 1-5                            [16, 128]                 2,097,280\n",
       "├─Dropout: 1-6                           [16, 128]                 --\n",
       "├─Linear: 1-7                            [16, 10]                  1,290\n",
       "==========================================================================================\n",
       "Total params: 2,117,962\n",
       "Trainable params: 2,117,962\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 351.30\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 12.60\n",
       "Params size (MB): 8.47\n",
       "Estimated Total Size (MB): 21.27\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Basic CNN in pytorch built with one dropout layer in the convolutional stack and one dropout layer in the classifier stack\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "class CNNWithDropout(nn.Module):\n",
    "    def __init__(self, n_classes = 10):\n",
    "        super(CNNWithDropout, self).__init__()\n",
    "        \n",
    "        # Assumptions:\n",
    "            # Input is 32 by 32\n",
    "            # Everywhere here the stride length is 1, and the padding is 1, which means\n",
    "            # the feature maps DO NOT change in terms of spatial size compared to the original\n",
    "            # dimensions of the image.\n",
    "            # The input and output dimensions are PER image. However the number of images\n",
    "            # (i.e. batch size) per pass is the 0th dimension even though its never explicitly shown.\n",
    "        \n",
    "        # Define the convolutional stack\n",
    "        \n",
    "        # Two convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 1) # Input = [32, 32, 3], Output = [32, 32, 32]\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1) # Input = [32, 32, 32], Output = [64, 32, 32]\n",
    "        \n",
    "        # One pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2) # This pooling layer will turn halve the spatial size of each channel: Input = [64, 32, 32], Output = [64, 16, 16]\n",
    "        \n",
    "        # One dropout layer with p = 0.25\n",
    "        self.dropout_conv = nn.Dropout2d(p = 0.25) # Dropout layers don't affect the shape of the data because they randomly zero out a set portion of the feature maps.\n",
    "        \n",
    "        # Define the classification stack\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        \n",
    "        self.dropout_fc = nn.Dropout(p = 0.5) # Similarly this dropout layer does not change the shape of the data,\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, n_classes) # Each of the prior 128 neurons connects to the last layer which contains raw logits for classification\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Pass through the convolution stack and apply appropriate activations (ReLU) along the way\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout_conv(x)\n",
    "        \n",
    "        # Flatten the final feature set but leave the 0th dimension (the batch size, i.e. the \"invisible dimension\")\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Pass through the classification stack and apply appropriate activations (ReLU) along the way\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout_fc(x) # Apply the dropout between the fully connected layers\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = CNNWithDropout(n_classes=10)\n",
    "summary(model, input_size=(16, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67494c76",
   "metadata": {},
   "source": [
    "**In the code above we used an auxillary library, `torchinfo`, in order to get an understanding of how data flows through our model and the size of the model itself, both in terms of parameters and physical storage size.**\n",
    "\n",
    "- The summary reveals that a vast majority of the parameters in our model originate from the linear layer located towards the end of the pipeline.\n",
    "\n",
    "- - This is very common among traditional CNN models.\n",
    "\n",
    "This is one reason why dropping some of these features in the classification stage is often more impactful than dropping parameters between convolutional layers!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb50ab8",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "Right now the data we are passing through the model is passed along in batched, often in batches of 32 or 64.\n",
    "\n",
    "- Recall that an *epoch* is how long it takes for all of the training data (which is chunked into batches) to make one pass through the model.\n",
    "\n",
    "However we can apply a simple technique to stabilize the results computed by each batch through each layer.\n",
    "\n",
    "- In basic statistics we learn the following:\n",
    "    - the mean of a set of values tells us its central tendency,\n",
    "    - the variance (or standard deviation) tells us how spread-out those values are.\n",
    "\n",
    "Batch Normalization (BatchNorm) takes advantage of these statistics at each layer, for each channel, to keep activations well-behaved. \n",
    "Here’s how it works, step by step, for a single feature map (channel) in a single layer:\n",
    "\n",
    "1) For a given channel, over a batch of size B and spatial dimensions H×W, we collect all the activations (all the outputs in the feature map, after applying ReLU)\n",
    "\n",
    "$$\\{x_{i,j,k}\\}, \\space i = 1 \\ldots B, \\space j = 1 \\ldots H, \\space k = 1 \\ldots W$$\n",
    "\n",
    "- - $B$ is the batch size.\n",
    "- - $H$ and $W$ are the image dimensions (height and width in pixels).\n",
    "\n",
    "2) Compute the statistical mean and variance of the batch\n",
    "\n",
    "$$\\mu_{\\text{batch}} = \\frac{1}{B \\cdot H \\cdot W} \\Sigma_{i, j, k}x_{i, j, k}$$\n",
    "\n",
    "$$\\sigma^2_{batch} = \\frac{1}{B \\cdot H \\cdot W} \\Sigma_{i, j, k}(x_{i, j, k} - \\mu_{batch})^2$$\n",
    "\n",
    "3) Use the computed values to normalize the scores. This is done by subtracting the mean and dividing by the variance.\n",
    "\n",
    "$$\\hat{x}_{i, j, k} = \\frac{x_{i, j, k} - \\mu_{\\text{batch}}}{\\sqrt{\\sigma^2_\\text{batch} +\\epsilon}}$$\n",
    "\n",
    "(This formula is applied to each score)\n",
    "\n",
    "Note that the **role of $\\epsilon$ is to apply a lower bound to the denominator** in case $\\sigma^2_\\text{batch}$ is so small that it is rounded to zero.\n",
    "\n",
    "$$\\sqrt{\\sigma^2 + e} \\ge \\sqrt{\\epsilon}$$\n",
    "\n",
    "- **The $\\epsilon$ value is hyperparameter that helps account for numerical instability**. We set it to a non-zero value to avoid division by zero errors.\n",
    "- - We can choose to use relatively high values for $\\epsilon$ such as $0.001$ or $0.0001$ if we see exploding gradients or division by zero errors often. Higher values for $\\epsilon$ aggresively normalizes activations to be closer to zero but this may reduce the range of gradients too directly.\n",
    "- - A smaller $\\epsilon$ keeps the effect of the variance more faithfully and is generally preferred if you have enough computer precision to avoid zeroing out the denominator.\n",
    "\n",
    "\n",
    "\n",
    "4) Batch normalization goes beyond basic standardizing and applies further transformations to the normalized score.\n",
    "\n",
    "- The prior normalized scores, $\\hat{x}_{i, j, k}$, are scaled and shifted using two hyperparameters: $\\gamma$ and $\\beta$\n",
    "\n",
    "$$y_{i, j, k} = \\gamma \\hat{x}_{i, j, k} + \\beta$$\n",
    "\n",
    "The two hyperparameters are trained using backpropogation alongside the rest of the model.\n",
    "\n",
    "4) During training we keep track of an exponential moving average of mean ($\\mu_{\\text{batch}}$) and variance $(\\sigma^2_{batch})$ across all samples using a momentum parameter.\n",
    "\n",
    "- **At test time use the running averages instead of the current batch's mean and variance.**\n",
    "\n",
    "Lets understand what this means for test time (i.e. when running the model in `model.eval()` mode)\n",
    "\n",
    "The exponential moving average for mean and variance are updated after processing some batch $t$ as follows:\n",
    "\n",
    "$$\\operatorname{EMA}_{\\mu}^{t + 1} = (1 - \\alpha) \\cdot r_{\\mu}^{(t)} + \\alpha \\mu^{(t)}$$\n",
    "$$\\operatorname{EMA}_{\\sigma^2}^{t + 1} = (1 - \\alpha) \\cdot r_{\\sigma^2}^{(t)} + \\alpha \\sigma^{2(t)}$$\n",
    "\n",
    "- Note that in the $t$ is not a parameter, it is just to indicate the nth term. So the second equation where it is written $\\sigma^{2(t)}$ DOES NOT INDICATE that we are multiplying some $t$ by 2, it is simply an indicator.\n",
    "\n",
    "- **$\\alpha$ is a momentum hyperparameter**\n",
    "- - A large $\\alpha$ means that newer, more recent, values are given more weight in calculating the EMA.\n",
    "- - A small $\\alpha$ means that change is slower to adapt to new data but also smoother over time.\n",
    "\n",
    "**The key insight is that in testing mode we use the finalized version of these EMAs from training instead of per batch values**\n",
    "\n",
    "$$\\hat{x}_{i, j, k} = \\frac{x_{i, j, k} - \\operatorname{EMA}_{\\mu}}{\\sqrt{\\operatorname{EMA}_{\\sigma^2} +\\epsilon}}$$\n",
    "\n",
    "Of course, afterwards this estimate is then scaled as described in step 4:\n",
    "\n",
    "$$y_{i, j, k} = \\gamma \\hat{x}_{i, j, k} + \\beta$$\n",
    "\n",
    "- This technique is practically identical to the ADAM (Adaptive Momentum) strategy that can be used to regularize gradient descent.\n",
    "\n",
    "**It is very important to understand that after the training process, all parameters: $\\operatorname{EMA}_{\\mu}, \\operatorname{EMA}_{\\sigma^{2}}, \\gamma, \\beta$ are all frozen.**\n",
    "\n",
    "- **We never update these parameters in the testing phase, we simply use the finalized versions of these parameters from training.**\n",
    "\n",
    "### In Practice\n",
    "\n",
    "The process described prior involves tuning and testing the *$\\alpha$* (momentum) and *$\\epsilon$* (instability) hyperparameters.\n",
    "\n",
    "**By default the value of $\\epsilon$ in PyTorch and Tensorflow is $0.00001$**\n",
    "\n",
    "The step of applying and training *affine* parameters to scale the activation after it has been normalized ($y_{i, j, k} = \\gamma \\hat{x}_{i, j, k} + \\beta$) is optional.\n",
    "\n",
    "- The scale and shift step is also more mathematically definable as an *affine transformation* by definition:\n",
    "\n",
    "- - A linear map must have the form $y = mx$ which always passes through the origin\n",
    "\n",
    "- - An affine map is simply a linear map with a constant shift: $y = mx + b$.\n",
    "\n",
    "- The *affine* step can be disabled by setting `affine = false` in the batch norm layer.\n",
    "\n",
    "Here are some general guidelines:\n",
    "\n",
    "- If your batch size is large (64 or greater), a higher value of $\\alpha$ (0.2-0.4) is useful to ensure that the running statistics recall trends from prior batches.\n",
    "\n",
    "- If your batch size is small (16 or lesser), a smaller value of $\\alpha$ (0.01-0.1) helps in getting smoother estimates and avoiding batch to to batch instability.\n",
    "\n",
    "- If you see exploding activations try increasing $\\epsilon$ to values a little larger values $0.0001$ or $0.001$.\n",
    "\n",
    "- **Batch normalization should be applied after determining the efects of the convolution, but before applying the ReLU activation function.**\n",
    "\n",
    "- Skip batch norm on the final classification layer (or use sparingly), since you don’t usually want to normalize logits.\n",
    "\n",
    "Of course none of this advice is perfect and toying around with these statistics to see which experiment provides the best outcomes for the particular data is always required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110be7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No BatchNorm  Test Loss: 0.0417  Test Acc: 98.58%\n",
      "With BatchNorm  Test Loss: 0.0465  Test Acc: 98.64%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1) Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2) Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_ds = datasets.MNIST('.', train=True,  transform=transform, download=True)\n",
    "test_ds  = datasets.MNIST('.', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "# 3) Models\n",
    "class TinyNoBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1   = nn.Linear(32*7*7, 128)\n",
    "        self.fc2   = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)); x = F.max_pool2d(x,2)\n",
    "        x = F.relu(self.conv2(x)); x = F.max_pool2d(x,2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "class TinyWithBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(32)\n",
    "        self.fc1   = nn.Linear(32*7*7, 128)\n",
    "        self.fc2   = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x))); x = F.max_pool2d(x,2)\n",
    "        x = F.relu(self.bn2(self.conv2(x))); x = F.max_pool2d(x,2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# 4) Train & Eval routines\n",
    "def train_epoch(model, loader, opt, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X,y in loader:\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()*X.size(0)\n",
    "    return total_loss/len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X,y in loader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            out = model(X)\n",
    "            total_loss += criterion(out,y).item()*X.size(0)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += pred.eq(y).sum().item()\n",
    "    return total_loss/len(loader.dataset), correct/len(loader.dataset)\n",
    "\n",
    "# 5) Run experiment\n",
    "def run_test(model_cls, name):\n",
    "    model = model_cls().to(device)\n",
    "    opt   = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    crit  = nn.CrossEntropyLoss()\n",
    "    for epoch in range(3):\n",
    "        train_loss = train_epoch(model, train_loader, opt, crit)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, crit)\n",
    "    print(f\"{name:>10s}  Test Loss: {test_loss:.4f}  Test Acc: {test_acc*100:5.2f}%\")\n",
    "\n",
    "run_test(TinyNoBN, \"No BatchNorm\")\n",
    "run_test(TinyWithBN, \"With BatchNorm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb47ce71",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data augmentation is by far the most straightforward yet potentially intricate ways to improve the robustness of any AI model.\n",
    "\n",
    "- The hypothesis: Perhaps the data fed into the model is not representative of an imperfect, real world, dataset. Therefore, when met with imperfect data the model may fail to achieve performance on par with its testing loop.\n",
    "\n",
    "- The solution: We can artifically apply transformations to portions of the training data to force the model to learn from imperfect examples that are more representative of real world data.\n",
    "\n",
    "Various types of adjustments can be made to visual data:\n",
    "\n",
    "| Type                        | Example                                     | Purpose                                |\n",
    "| --------------------------- | ------------------------------------------- | -------------------------------------- |\n",
    "| **Geometric**               | Flips, rotations, translations, cropping    | Invariance to position/orientation     |\n",
    "| **Color/Lighting**          | Brightness, contrast, saturation, hue shift | Invariance to illumination             |\n",
    "| **Noise/Blur**              | Gaussian noise, motion blur                 | Robustness to imperfect images         |\n",
    "| **Scaling**                 | Zoom in/out                                 | Invariance to object size              |\n",
    "| **Cutout / Random erasing** | Mask out random patches                     | Force focus on global features         |\n",
    "| **Mixup / CutMix**          | Combine pairs of images & labels            | Encourage smoother decision boundaries |\n",
    "\n",
    "Beyond simple visual data:\n",
    "\n",
    "- We can make adjustments to written data by replacing words with synonyms, translating to other languages or slang, or randomly inserting / deleting words or phrases.\n",
    "- We can also transform audio data by applying shifting, pitch scaling, or adding / removing distortion or background noise.\n",
    "\n",
    "This list of transformations is by no means exhaustive but should inform you on how data diversity can be achieved by generating synthetic, modified, inputs from the original data.\n",
    "\n",
    "`torchvision` is a library which contains the `transforms` package to quickly define a set of transformations which can be applied to a dataset.\n",
    "\n",
    "Here is some example code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6422862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "# Compose several augmentations together\n",
    "transform_train = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.RandomRotation(15),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# Apply this to your dataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ec0db",
   "metadata": {},
   "source": [
    "Of course **we should not train our model so much on imperfect data that the model becomes confused regarding classification tasks**.\n",
    "\n",
    "- It is important to ensure diversity in the data without doing so in an unrealistic way.\n",
    "\n",
    "Ex. Rotating 20% of the digits in the MNIST dataset by 180 degrees.\n",
    "\n",
    "- Ask yourself, in the real world, what percentage of people write their numbers upside down? Is it anywhere near the percentage of misleading data we are provided the model?\n",
    "\n",
    "- The bottom line: **Don’t just randomly apply all augmentations, instead try to use transformations your model will need to handle in deployment.**\n",
    "\n",
    "### Mixup Augmentation\n",
    "\n",
    "One specialized non-geometric way that we can choose to modify our dataset is to pair up and combine two inputs to synthesize a new image.\n",
    "\n",
    "*Mixup* is a technique that samples two random images and their respective labels and combines then combines them based on a weighted parameter: $\\lambda$.\n",
    "\n",
    "For one pair of input and label $(x_i, y_i)$ and another input and label $(x_j, y_j)$ we can combine them as follows\n",
    "\n",
    "$$x_{\\text{combined}} = \\lambda \\cdot x_i + (1 - \\lambda) x_j$$\n",
    "$$y_{\\text{combined}} = \\lambda \\cdot y_i + (1 - \\lambda) y_j$$\n",
    "\n",
    "**The weight parameter $\\lambda$ is randomly drawn from a beta distribution with a mean and variance of $\\alpha$ (which is typically some value from $0.1-0.4$)**\n",
    "\n",
    "$$\\lambda ∼ \\operatorname{Beta}(\\alpha, \\alpha)$$\n",
    "\n",
    "The following is a direct quote from the original paper that proposed the *mixup* technique:\n",
    "\n",
    "```text\n",
    "\n",
    "\"While data augmentation consistently leads to improved generalization (Simard et al., 1998), the procedure is dataset-dependent, and thus requires the use of expert knowledge. Furthermore, data augmentation assumes that the examples in the vicinity share the same class, and does not model the vicinity relation across examples of different classes.\"\n",
    "\n",
    "Source:\n",
    "    \n",
    "    mixup: Beyond Empirical Risk Minimization (Zhang, Cisse, et. al)\n",
    "\n",
    "```\n",
    "\n",
    "Traditional data augmentation methods (e.g. rotation, flipping, cropping) work by generating new examples that are small transformations of existing ones.\n",
    "\n",
    "- These methods rely on the assumption that such transformations preserve the label.\n",
    "- But this assumption:\n",
    "- - **Requires dataset-specific knowledge** (e.g. what transformations are safe to apply)\n",
    "- - Can **break down for ambiguous or similar classes**\n",
    "\n",
    "Consider the example:\n",
    "\n",
    "- The digits 6 and 9 can be transformed into one another by a simple 180-degree rotation.\n",
    "\n",
    "- If you apply **180-degree rotation as a data augmentation blindly, you risk turning a correctly labeled 6 into something that looks like a 9 → introducing label noise unintentionally.**\n",
    "\n",
    "Mixup smoothly blends between classes in a principled way. It explicitly models vicinity across examples of different classes (e.g. what a sample that’s 70% cat and 30% dog should look like).\n",
    "\n",
    "The benefits of Mixup include:\n",
    "\n",
    "- **Dataset agnostic:** No need for expert domain knowledge to choose safe augmentations.\n",
    "\n",
    "- **Reduces overfitting:** Encourages the model to behave linearly between training samples.\n",
    "\n",
    "- **Robustness:** Improves resistance to adversarial examples and noisy labels.\n",
    "\n",
    "- **Smooth decision boundaries:** Instead of sharp transitions between classes, the model learns gradual transitions, improving generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code example of how to apply Mixup to a batch of data points\n",
    "\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \n",
    "    # Sample lambda from a Beta distribution to determine the mix ratio\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    \n",
    "    # Get the number of samples in the batch\n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    # Generate a random permutation of the batch indices for pairing\n",
    "    # Example: for batch indices [0, 1, 2, 3], this could produce [2, 0, 3, 1]\n",
    "    index = torch.randperm(batch_size)\n",
    "\n",
    "    # Mix each input with its randomly paired input\n",
    "    # Example: x[0] mixes with x[2], x[1] mixes with x[0], etc.\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "\n",
    "    # Pair the labels for later use in the mixed loss calculation\n",
    "    # We don’t mix the labels here numerically because the model’s prediction\n",
    "    # is needed to compute loss first (the mixing happens in the loss function)\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# Example usage in training:\n",
    "pred = model(mixed_x)  # Make predictions on the mixed inputs\n",
    "\n",
    "# Compute the mixed loss: the model is encouraged to output a blend matching the input mix\n",
    "loss = lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb46f6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAEGCAYAAACeiKhrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAALD9JREFUeJzt3Xd8VFXex/HvkEqo0ptUBQTNRgKCAhK6tF1pi6BIs1EWV11UHkGKUlRwAzZ0pUlVQUREAYEIFkQQVMrqIsIiiFIDoQRIcp4/fJKHITn3JJNAAnzer1deL7jfe849M5Mz+c2dO2d8xhgjAAAAAFb5cnsAAAAAQF5H0QwAAAA4UDQDAAAADhTNAAAAgANFMwAAAOBA0QwAAAA4UDQDAAAADhTNAAAAgANFMwAAAOBA0QwAACBpxowZ8vl88vl8+vTTT9Plxhhdd9118vl8iomJSdvu8/k0cuTISzZO5I7g3B4AAABAXlKoUCFNnTrVrzCWpDVr1mjnzp0qVKiQ3/Z169apQoUKl3CEyA2caQYAADhPt27dtHDhQh0/ftxv+9SpU3XrrbeqYsWKftsbNGhA0XwVoGgGAAA4T/fu3SVJ8+bNS9t27NgxLVy4UH379k23//mXZxhj1LZtWxUvXlx79uxJ2+fUqVOqXbu2brjhBp08eVKS1Lt3b1WuXDldfyNHjpTP50t3jEGDBun1119X9erVFRYWplq1amn+/PnZvbnIJIpmAACA8xQuXFhdunTRtGnT0rbNmzdP+fLlU7du3Tzb+nw+zZo1SxEREfrrX/+qc+fOSZIGDBigXbt26Z133lGBAgUCGtcHH3ygyZMna/To0VqwYIEqVaqk7t27a8GCBQH1h6zhmmYAAIAL9O3bV02bNtW2bdtUu3ZtTZs2TV27dk13PXNGihcvrvnz5ysmJkaPP/64IiMjNXPmTL355pu66aabAh7ToUOHtGHDBpUuXVqS1LZtW914440aOnSounTpEnC/yBzONAMAAFygSZMmqlatmqZNm6YtW7Zow4YNGV6aYdOwYUONGTNGsbGx6t+/v+655x7169cvW2Nq3rx5WsEsSUFBQerWrZt++ukn7d27N1t9w42iGQAA4AI+n099+vTR7NmzNWXKFFWvXl2NGzfOUh933323QkNDdebMGQ0ZMiTbYypTpox12+HDh7PdP7xRNAMAAGSgd+/eOnTokKZMmaI+ffpkqW1ycrLuvvtuXXPNNapYsaL69euns2fP+u0THh6uM2fOpGt76NChDPv87bffrNuKFy+epfEh6yiaAQAAMlC+fHkNGTJEHTp0UK9evbLUdsSIEfrss880Z84cvf322/ruu+/SnW2uXLmyDhw4oN9//z1t29mzZ7V8+fIM+1y1apXfvsnJyXr77bdVrVo1lry7BCiaAQAALMaPH6/3339fZcuWzXSbTz75ROPGjdPw4cPVvHlzNWjQQOPGjdPkyZO1aNGitP26deumoKAg3XXXXfroo4/03nvvqVWrVkpOTs6w3xIlSqhZs2aaP3++lixZovbt2+uHH37QmDFjsn074UbRDAAAkEP279+ve+65RzExMXr66afTtj/66KPq0KGD+vbtq927d0uSqlSposWLFys+Pl5dunTRkCFD1LVrV917770Z9v3nP/9ZgwYN0rBhw9S5c2ft3r1bc+bMcS6Dh5zhM8aY3B4EAAAA7Hw+nwYOHKiXX345t4dy1eJMMwAAAOBA0QwAAAA48I2AAAAAeRxX0+Y+zjQDAAAADnmqaP7qq6/UtWtXlS1bVqGhoSpTpoy6dOmidevWZamfkSNHyufzBTSGTz/9VD6fT59++mlA7TMrJiZGMTExzv0+//xz3XfffYqOjlZYWJh8Pl/ap24zKz4+XiVKlND8+fPTtqXeR7YF1LNi9+7d8vl8mjBhQrb7urDPGTNmOPf1+XwZ/owfP95vv+HDh6tOnTpKSUnJsXEic5jb/pKTk/Xiiy/qjjvuUIUKFRQREaEbbrhBTz75pOLj4zN9rCt9bkvSSy+9pJo1ayosLExVqlTRqFGjdO7cOb99mNt534kTJ/T3v/9d5cqVU3h4uKKiovx+b13i4uLUsmVLlSpVSgULFlRkZKQmT55sXZpNkk6fPq3q1at7/g7v3r3bOl9jYmIy/Ntyxx13ZHrcOWnlypW69dZbFRERoRIlSqh37946cOBAptq+9dZbuuuuu1SjRg3ly5dPlStX9tz/888/V9u2bXXNNdcof/78uv766/XMM89kuG/v3r2tz6vZfdzzmjxTNL/00ktq2LCh9u7dq+eff14rV67UhAkTtG/fPjVq1ChLnxa97777svzHOFWdOnW0bt061alTJ6D2OW3VqlVauXKlKlasqNtuuy2gPkaNGqVy5cpd0UvSpBZg5/9cuGTPP/7xD+3atUszZ87MpVFenZjb6Z0+fVojR45UpUqVFBsbq48++kj333+/3njjDTVs2FCnT5/OVD9X+tweM2aMHn74YXXq1EnLly/XgAEDNHbsWA0cONBvP+Z23tepUyfNnDlTI0aM0Mcff6x69eqpe/fumjt3rrPtypUr1aJFCyUlJelf//qX3n//fcXExOjhhx/Wo48+am03fPhwnTx5Mt32I0eOaOzYsemy7du3a/LkyX7bqlatmu5vS2xsbOZudA5as2aN2rRpo9KlS2vx4sWaNGmSVq5cqebNm2f4jYIXmjVrlrZt26ZbbrlF1apV89x37ty5atKkiYoUKaK33npLH330kZ544gm/y0NmzpyZ7rn43Llzmjx5snbs2JG2LTuPe55k8oDPP//c5MuXz7Rv396cO3fOLzt37pxp3769yZcvn/n88889+zl58uTFHGaOatKkiWnSpIlzv+Tk5LR/v/DCC0aS2bVrV6aPc/jwYZM/f34zZcoUv+0jRowwkszBgwcz3ZfNrl27jCTzwgsvZLuvC/ucPn26c19JZuDAgZnqd9CgQaZ69eomJSUlmyNEZjC3M5aUlGQOHTqUbvu7775rJJlZs2Y5j3Olz+1Dhw6Z8PBw88ADD/htHzNmjPH5fGbbtm1+25nbedfSpUuNJDN37ly/7S1btjTlypUzSUlJnu3vvvtuExYWZk6cOOG3vVWrVqZw4cIZtlm/fr0JDQ1Nm1Pn/w6fPHnSPPfccyYqKsqMHj3aREVFmYceesjExMSYVatWpe3XpEkTU7t27azeXKvp06ebQMuuevXqmVq1avk9j37xxRdGknn11Ved7c+vJdq1a2cqVaqU4X579+41BQoUMP379/fs7+uvvzbt2rUz3bp1My1btjSPP/64qVu3rhk2bJg5evSoMSb7j3telCfONI8bN04+n0+vvfaagoP9P5sYHBysV199Nd3b7alvQW7atEldunTRNddck/bqKaO3cM+cOaPHHntMZcqUUUREhG6//XZ98803qly5snr37p22X0Zv4fbu3VsFCxbUTz/9pLZt26pgwYK69tpr9dhjj6V7hTdq1CjVr19fxYoVU+HChVWnTh1NnTo14Av48+XL3kM0Y8YMJSUlBXQm6uDBgxowYIBq1aqlggULqlSpUmrWrJk+++yzDPdPSUnRmDFjVLFiRYWHh6tu3bpatWpVuv127NihHj16qFSpUgoLC9MNN9ygV155JcvjC0TPnj31n//8R3FxcZfkeFc75nbGgoKCVLx48XTbb7nlFknSL7/84uzjSp/by5YtU2Jiovr06eO3vU+fPjLG6P333/fbztzOuxYtWqSCBQuqa9euftv79OmjX3/9VevXr/dsHxISotDQUOXPn99ve9GiRRUeHp5u/7Nnz6pv374aOHCg6tatmy6PiIjQ448/rhUrVujdd9/Vt99+q6JFiyouLk7NmjUL4BZeXPv27dOGDRvUs2dPv+fR2267TdWrV/f7hkGbzNYSb775pk6ePKknnnjCc7969erpww8/VJMmTbRy5UrNnTtX8+fP1zPPPKOiRYtKyv7jnhfletGcnJysuLg41a1b1/q96ddee62io6O1evXqdNcvderUSdddd53effddTZkyxXqcPn36KDY2Vn369NHixYvVuXNndezYMdPXD547d05//vOf1bx5cy1evFh9+/bVP//5Tz333HN+++3evVsPPvig3nnnHb333nvq1KmT/va3v1mvBbrYli5dqptvvjntlzgrjhw5IkkaMWKEli5dqunTp6tq1aqKiYnJ8Pqll19+WcuWLVNsbKxmz56tfPnyqU2bNn5v4Wzfvl316tXT1q1bNXHiRH344Ydq166dBg8erFGjRgV6MzV37lzlz59fYWFhio6O1vTp0zPcLzo6WgULFtTSpUsDPhYyh7mddatXr5Yk1a5d27nvlT63t27dKkm66aab/LaXLVtWJUqUSMtTMbfzrq1bt+qGG25I98I5MjIyLffy0EMP6ezZsxo8eLB+/fVXxcfHa9asWVq0aJEef/zxdPuPHj1aJ0+etM7N06dP68UXX1Tr1q3VtWtXRUVF6ejRo2rWrFm6F107d+5UsWLFFBwcrGrVqumpp57K9OVTOSX1/km9v84XGRnpvP+yYu3atSpWrJh++OEHRUVFKTg4WKVKldJDDz2k48ePp+23adMm/eUvf9Gnn36qFi1aqEePHrrrrrv09NNPpz33Zvdxz5Ny+Uy3+e2334wkc9ddd3nu161bNyPJ/P7778aY/38L8umnn063b2qWatu2bUaSeeKJJ/z2mzdvnpFkevXqlbYtLi7OSDJxcXFp23r16mUkmXfeecevfdu2bU2NGjWsY05OTjbnzp0zo0ePNsWLF/d72zCzl2ecL5DLMyIiIsxDDz2Ubnsgb+EmJSWZc+fOmebNm5uOHTumbU99u7VcuXLm9OnTaduPHz9uihUrZlq0aJG2rXXr1qZChQrm2LFjfn0PGjTIhIeHmyNHjvj1mZnLM3r06GHmzJlj1q5daxYsWGDatGljJJlhw4ZluH/Dhg1N/fr1M327ERjmdtbs3bvXlC5d2tStW9fvrVSbK31u33///SYsLCzDrHr16qZVq1bptjO386brr7/etG7dOt32X3/91UgyY8eOdfbxxRdfmHLlyhlJRpIJCgoyzz//fLr9Nm/ebEJCQsyyZcuMMRlfYnTo0CHz7LPPmhMnTphdu3alzddt27aZSZMmpe331FNPmVdffdWsXr3aLF261AwaNMgEBweb22+/PVNzNHVepf5MnTrVSPLbdu7cOWdfc+bMMZLMunXr0mUPPPCACQ0NdY7lfF6XZ9SoUcOEh4ebQoUKmbFjx5q4uDjz/PPPm/z585uGDRumPdfNmDHDfPnll8aYP55H4+LizNmzZ82kSZPMf/7zH2NMzjzueU2un2nOLPN/b4Fe+NZs586dnW3XrFkjSfrrX//qt71Lly7pXgHZ+Hw+dejQwW9bZGSk/vvf//ptW716tVq0aKEiRYooKChIISEhevrpp3X48OFMf8o1p8THx+vUqVMqVapUwH1MmTJFderUUXh4uIKDgxUSEqJVq1bp3//+d7p9O3Xq5PdWWaFChdShQwetXbtWycnJSkxM1KpVq9SxY0dFREQoKSkp7adt27ZKTEzUV199leUxzpkzRz169FDjxo3VuXNnffTRR2rfvr3Gjx+vgwcPptu/VKlS2rdvX5aPg4uDuf3Hmd+2bdvKGKO3337b+Vbq1TK3vVZKyShjbuddWX0sz/fNN9+oY8eOio6O1pIlS7R69WoNHTpUw4YN8zubnJSUpL59+6pbt25q3bq1tb/ixYvrqaeeUoECBfy216pVS4MHD077/7PPPqv+/furadOmatu2rV566SWNHz9ea9eu1eLFi103WdWqVVNISEjaT79+/STJb1tISIhGjx7t7Euy30+BriiUkZSUFCUmJup//ud/NHToUMXExGjIkCEaN26cvvjii7TLsnr16qVbb73Vr21ISIgGDx6s66+/PlNjy8lxXyq5XjSXKFFCERER2rVrl+d+u3fvVkREhIoVK+a3vWzZss5jHD58WJJUunRpv+3BwcEZXleYkYiIiHTXToWFhSkxMTHt/19//bVatWolSfrXv/6lL774Qhs2bNBTTz0lSZf8LZ3U42V0zVdmvPjii+rfv7/q16+vhQsX6quvvtKGDRt0xx13ZHhbypQpk+G2s2fP6sSJEzp8+LCSkpL00ksvpXvSaNu2rSTlyDJZknTPPfcoKSlJGzduTJeFh4df8sfiasTczpyjR4+qZcuW2rdvnz755BNVrVrV2eZqmNvFixdXYmKiTp06lS47cuRIut8XibmdVxUvXjxtrp4v9TKhjB7L8w0cOFClS5fWokWL1L59ezVt2lTPPPOMnnzySY0cOVI///yzJCk2NlY///yzRowYofj4eMXHx6ddUpCYmKj4+Ph0l4FVrlw5S8tQ3nPPPZKUqReBS5Ys0YYNG9J+RowYIUl+2zZs2KAHHnjAs5/U5zLbfei6/7Ii9VgXvuho06aNpD8uy7jQjBkzMly2L7uPe16U698IGBQUpKZNm2rZsmXau3dvhtc+7t27V998843atGmjoKAgvywzr1RSfwl+//13lS9fPm17UlJShg9ooObPn6+QkBB9+OGHfn/MLvzAyqWSertTf0Gzavbs2YqJidFrr73mtz0hISHD/X/77bcMt4WGhqpgwYIKCQlRUFCQevbsmW7JqFRVqlQJaKwXSj17mdEZuyNHjqhEiRI5chzYMbfdjh49qhYtWmjXrl1atWpVhtcsZuRqmNup1zJv2bJF9evX9zvuoUOHdOONN6Zrw9zOm2666SbNmzdPSUlJfu8AbdmyRZIyfCzP9+2336p79+7pniPq1aunlJQU/fvf/1bVqlW1detWHTt2zO9MZ6rhw4dr+PDh2rx5s6KiorJ9mzLzwboLr8dPvYY3ow8nekm9f7Zs2ZL2IjTVli1bnPdfVkRGRmb4gsDrb6pNdh/3vCjXzzRL0tChQ2WM0YABA9K9CkxOTlb//v1ljNHQoUMD6v/222+XJL399tt+2xcsWKCkpKTABp0Bn8+n4OBgv4l9+vRpzZo1K8eOkRWhoaGqWrWqdu7cGVB7n8+nsLAwv23ff/+9dZ3c9957z+/sXEJCgpYsWaLGjRsrKChIERERatq0qTZv3qzIyEjVrVs33U9mzw66zJo1SyEhIYqOjk6X/fzzz6pVq1aOHAfemNt2qQXzzz//rBUrVujmm2/OdNurYW7fcccdCg8PT/clKDNmzJDP59Odd96Zrg1zO2/q2LGjTpw4oYULF/ptnzlzpsqVK+f3oigj5cqV08aNG9M9h6T+vqa+IH/yyScVFxfn9zNv3jxJf3yYMC4uTtddd122bkvqWuANGjTIVj9ZUb58ed1yyy2aPXu2333w1Vdf6ccff1SnTp1y7Fipl8V9/PHHfts/+ugjSVm73dl93POiXD/TLEkNGzZUbGys/v73v6tRo0YaNGiQKlasqD179uiVV17R+vXrFRsbG/CXe9SuXVvdu3fXxIkTFRQUpGbNmmnbtm2aOHGiihQpku1l3VK1a9dOL774onr06KEHHnhAhw8f1oQJE9L9ccqKgwcPpl23mfrq7OOPP1bJkiVVsmRJNWnSxLN9TExMul/+8y1ZskSFChVKt71Lly5q3769nnnmGY0YMUJNmjTRjz/+qNGjR6tKlSoZFiRBQUFq2bKlHn30UaWkpOi5557T8ePH/T45P2nSJDVq1EiNGzdW//79VblyZSUkJOinn35Ku1YtK1544QVt375dzZs3V4UKFXTgwAFNnTpVK1as0MiRI9OddTp8+LB27Nihv/3tb1k6DgLD3M7Y6dOn1bp1a23evFmxsbFKSkryO7tTsmRJ5xcQXOlzu1ixYho2bJiGDx+uYsWKqVWrVtqwYYNGjhyp++67L11xzNzOu9q0aaOWLVuqf//+On78uK677jrNmzdPy5Yt0+zZs/1ejPbr108zZ87Uzp07ValSJUnSI488osGDB6tDhw568MEHFRERoVWrVmnixIlq0aKF/vSnP0mSatasqZo1a/odO/UbdKtVq5apb+FN9dlnn2nMmDHq2LGjqlatqsTERH388cd644031KxZs3Sfg7jYnnvuObVs2VJdu3bVgAEDdODAAT355JO68cYb/ZZl/O9//6tq1aqpV69emjp1atr27du3a/v27ZL+eLfm1KlTWrBggaQ/ruVOnU+tWrVShw4dNHr0aKWkpKhBgwbauHGjRo0apfbt26tRo0aZHnNWHvfLRq59BDED69atM126dDGlS5c2wcHBplSpUqZTp05pn9A8n9cnxC/8hL0xxiQmJppHH33UlCpVyoSHh5sGDRqYdevWmSJFiphHHnkkbT/bJ+wLFCiQqeNMmzbN1KhRw4SFhZmqVauacePGpX1i9vxVLzL7CfvU8WT0k5n2q1atMpLM119/neHYbT/GGHPmzBnzj3/8w5QvX96Eh4ebOnXqmPfff9/06tXL75O3qZ9Ofu6558yoUaNMhQoVTGhoqLn55pvN8uXL041p165dpm/fvqZ8+fImJCTElCxZ0tx2223m2WefTden6xP2H3zwgWnUqJEpWbKkCQ4ONoUKFTKNGzc28+bNy3D/qVOnmpCQEPPbb7857zvkHOa2v9Tfb9vP+at+2FzpczvVpEmTTPXq1U1oaKipWLGiGTFihDl79my6/ZjbeVtCQoIZPHiwKVOmjAkNDTWRkZEZPk+nrmhz4SpRCxcuNI0aNTIlSpQwBQoUMLVr1zbPPPNMui88uVCgX9CzY8cO07ZtW1O+fHkTFhZmwsPDzU033WTGjBljEhMTs9RXqux8uYkxxqxYscI0aNDAhIeHm2LFipl77703bdWhVKm398LnEK/nhREjRvjte+rUKfPEE0+Ya6+91gQHB5uKFSuaoUOHBnS7M/u4Xy58xgT4rRtXgC+//FINGzZMW33hShUZGamGDRumu37xatS4cWNVrFhRc+bMye2h4CJibl99mNsALrarpmj+5JNPtG7dOkVHRyt//vz67rvvNH78eBUpUkTff/99wJ9CvxwsW7ZMHTt21I4dO6xfMnE1WLt2rVq1aqXt27dnaoUCXB6Y28xt5jaASyFPXNN8KRQuXFgrVqxQbGysEhISVKJECbVp00bjxo27ov+oSn98oOaFF17Qrl27ruo/rIcPH9Zbb73FH9UrDHObuc3cBnApXDVnmgEAAIBA5Ykl5wAAAIC8jKIZAAAAcKBoBgAAABwomgEAAACHTK+e4fP5LuY4gCtSXv+cLfMayDrmNXDlycy85kwzAAAA4EDRDAAAADhQNAMAAAAOFM0AAACAA0UzAAAA4EDRDAAAADhQNAMAAAAOFM0AAACAA0UzAAAA4EDRDAAAADhQNAMAAAAOFM0AAACAA0UzAAAA4EDRDAAAADhQNAMAAAAOFM0AAACAA0UzAAAA4EDRDAAAADhQNAMAAAAOFM0AAACAA0UzAAAA4EDRDAAAADhQNAMAAAAOFM0AAACAA0UzAAAA4EDRDAAAADhQNAMAAAAOwbk9AABA1kRHR3vmgwYNsmb33nuvNXvrrbc8+33ppZes2aZNmzzbAvAWHh7umRcrVsyaFS5c2JodP37cs98jR45Ys8TERM+2VxvONAMAAAAOFM0AAACAA0UzAAAA4EDRDAAAADhQNAMAAAAOFM0AAACAA0UzAAAA4OAzxphM7ejzXeyxXNWCgoI88yJFilyU43qt5xoREWHNatSo4dnvwIEDrdmECROsWffu3T379Vozcvz48Z5tR40a5ZlfDJmcXrmGeZ13RUVFWbPVq1d7tvVaszU7jh07Zs2KFy9+UY6ZFzGvr2758nmfbyxUqJA181qLuVKlSp799uzZ05rlz5/fmlWpUsWz3xEjRlizO++805q1a9fOs9+zZ89aszfeeMOz7SuvvOKZXwyZmdecaQYAAAAcKJoBAAAAB4pmAAAAwIGiGQAAAHCgaAYAAAAcKJoBAAAAh+DcHkBeVLFiRWsWGhrq2fa2226zZo0aNbJmRYsW9ey3c+fOnvmltnfvXs988uTJ1qxjx47WLCEhwbPf7777zpqtWbPGsy2Q19xyyy3WbOHChdbMtQSl19JJXnPMa4koyXtZuQYNGlizTZs2efbrOi5gU7ZsWWsWEhLi2fbmm2+2ZtHR0dbMa0k5yXuZtgoVKliz4ODAS7KUlBRr9uuvv3q29Vpy7rrrrrNmR44c8ez3hx9+sGYbNmzwbJtXcaYZAAAAcKBoBgAAABwomgEAAAAHimYAAADAgaIZAAAAcKBoBgAAABx8xmttovN39Pku9lgumaioKM989erV1sy11NOVxGsJm759+3q2PXHiREDH3L9/v2d+9OhRa/bjjz8GdMyLKZPTK9dcSfM6t0RERFizOnXqeLadPXu2NfNamsr1uHn93nkt//b888979jt//vyAxjRs2DDPfseNG+eZ5zXM60unZs2anvnMmTOtmWtpOC9e92H+/Pk925YvX96aZWdZOS+nTp2yZg8++KBnW6+lJL1s3brVM9+5c6c12717d0DHvJgyM6850wwAAAA4UDQDAAAADhTNAAAAgANFMwAAAOBA0QwAAAA4UDQDAAAADhTNAAAAgMPFWTAwj9uzZ49nfvjwYWuWF9dpXr9+vTWLj4/3bNu0aVNrdvbsWWs2a9Ys57iAq8Hrr79uzbp3734JR5I5XmtHFyxY0LPtmjVrrFlMTIw1i4yMdI4LyIhr7X6vv3HZWae5XLly1qxw4cIB9/v9999bs+PHj3u2rV+/fkDHXLJkiWdetGhRa+a1JnVCQoJnv/v27fPML0ecaQYAAAAcKJoBAAAAB4pmAAAAwIGiGQAAAHCgaAYAAAAcKJoBAAAAh6tyybkjR4545kOGDLFm7du392y7efNmazZ58mTvgXn49ttvrVnLli2t2cmTJz37rV27tjV7+OGHneMCrgbR0dHWrF27dtbM5/MFfEyv5d1cS0hNmDDBmv3666/WzOv5S5KOHj1qzZo1a2bNsnM/4Op27Ngxz/z555+3Zl7LIErS7t27rdkbb7zh2dbLDz/8YM26detmzQ4cOODZb6NGjaxZjx49rFliYqJnv1410bXXXuvZ9mrDmWYAAADAgaIZAAAAcKBoBgAAABwomgEAAAAHimYAAADAgaIZAAAAcKBoBgAAABx8xhiTqR1ZZ1OSVLhwYc88ISHBmr3++uvWrF+/fp793nPPPdZs3rx5nm2RezI5vXIN8/oPUVFRnvnq1autmes5wcvHH39szbp3727NmjRp4tlvZGSkNXvzzTet2cGDBz379ZKcnGzNTp065dnW6/Zs2rQp4DFdLMzry0Px4sU985IlS1qzZ5991pp17tzZs98BAwZYsylTplizAgUKePYbFhZmzeLj462Z19x0qVmzZsBtvdbBdq0dnRsyM6850wwAAAA4UDQDAAAADhTNAAAAgANFMwAAAOBA0QwAAAA4UDQDAAAADsG5PYDLzfHjxwNue+zYsYDb3n///dbs7bfftmYpKSkBHxO4klSvXt2aDRkyxLNtkSJFrNmhQ4es2f79+z37nTlzpjU7ceKENVu6dKlnv678UsufP79n/thjj1mzu+++O6eHgytIaGioNQsPDw+4X68l3M6cOePZtmXLltbMa8k5rzmfmTyv8Vryb9++fZdwJDmHM80AAACAA0UzAAAA4EDRDAAAADhQNAMAAAAOFM0AAACAA0UzAAAA4MCSc5fQyJEjrVl0dLRn2yZNmlizFi1aWLMVK1Y4xwVcCcLCwjzzCRMmWLO2bdt6tk1ISLBm9957rzXbuHGjZ7+updiuFhUrVsztISCP8vl8nnnp0qWtWYECBTzbGmOs2dChQ62Z67mmfv361uy2226zZl988YVnv5ebkJCQ3B5CjuNMMwAAAOBA0QwAAAA4UDQDAAAADhTNAAAAgANFMwAAAOBA0QwAAAA4UDQDAAAADj7jtVDh+Ts61kpE9lSrVs0z37RpkzWLj4+3ZnFxcZ79eq0j+8orr1izTP7aXPXy+v10Jc3rBg0aeOaff/55wH03b97cmq1Zsybgfq8kycnJ1sw1D9atW2fNGjduHPCYLhbm9aXjWsu8UqVKAfe9Z88ea3bq1Clrdu2113r2u2jRImt2/Phxa7Z+/XrPfrdu3WrN5syZ49k2UDVr1gy4bWJiojXbvXt3wP1eLJmZ15xpBgAAABwomgEAAAAHimYAAADAgaIZAAAAcKBoBgAAABwomgEAAACH4NweAP6wc+dOz7x3797WbPr06dasZ8+env165QUKFLBmb731lme/+/fv98yBnPbiiy965l7LcLmWjWNZObd8+eznYFJSUi7hSHAlKV26dMBtT58+7Zl7LSvn5ZdffvHMn3zySWs2btw4a/aXv/zFs1+v3GtpvsWLF3v2e/DgQWvGvPbHmWYAAADAgaIZAAAAcKBoBgAAABwomgEAAAAHimYAAADAgaIZAAAAcGDJucvEokWLrNmOHTusmWsZrubNm1uzsWPHWrNKlSp59jtmzBhrtm/fPs+2gE379u2tWVRUlGdbY4w1++CDDwIdEv6P1/JTXve9JH377bc5PBpcTgoWLGjNwsPDA+43ISEh4LbZsXLlSmu2Z88ea/bEE0949nvrrbdas0cffdSalS9f3rPf1157zZplZ1m5xMTEgNvmVZxpBgAAABwomgEAAAAHimYAAADAgaIZAAAAcKBoBgAAABwomgEAAAAHimYAAADAwWdcC2im7ujzXeyx4CIoWrSoZ96hQwdrNn36dGvm+n1YvXq1NWvZsqVn2ytJJqdXrrnc5nXXrl2t2bx58zzbHjhwwJpFR0d7tt2/f7/3wK4QYWFhnvnIkSOt2eOPP27NVq1a5dlvp06drNmJEyc82+YG5nXOKly4sDUrV66cZ9ukpCRrtnv37oDb5oZChQp55k2bNrVm48aNs2b58nmfH/3pp5+s2ZAhQ6zZqVOnPPv95ZdfrFlenEOZGRNnmgEAAAAHimYAAADAgaIZAAAAcKBoBgAAABwomgEAAAAHimYAAADAgSXnYHXmzBlrFhwc7NnWaymf1q1bW7NPP/3UOa7LSV5cVud8l9u8zs6Sc17LH1WpUiXgMV1uvJaVGzZsmGfboUOHWrN9+/ZZswceeMCz3+XLl3vmeQ3zOmddrCXnvJZSu9Js2bLFmpUpU8az7TXXXGPNevXqZc3ef/99z35Pnjzpmec1LDkHAAAA5ACKZgAAAMCBohkAAABwoGgGAAAAHCiaAQAAAAeKZgAAAMDBe90wXBYiIyOtWZcuXTzb1qtXz5q5lpXzsn37dmu2du3agPsFAvXBBx/k9hAumaioKGs2ZMgQa9atWzfPfhcvXmzNOnfu7BwXkNMSEhJyewhZUr16dWt2xx13eLatW7euNatYsaI181rST5I2btxozebOnWvN8vrSixcDZ5oBAAAAB4pmAAAAwIGiGQAAAHCgaAYAAAAcKJoBAAAAB4pmAAAAwIGiGQAAAHBgneY8okaNGp75oEGDrFmnTp2sWZkyZQIek5fk5GTPfP/+/dYsJSUlp4eDq4TP5wsok6Q777zTmj388MOBDilXPPLII5758OHDrVmRIkWs2Zw5czz7vffee70HBlxihQoVsma///77RTlm5cqVPfOePXtasxYtWlizmjVrevZbokQJa5Yvn/0c6NGjRz373bx5szW7Gtdi9sKZZgAAAMCBohkAAABwoGgGAAAAHCiaAQAAAAeKZgAAAMCBohkAAABwYMm5HOa1xFv37t2tmdeScpJ7iZuLYePGjdZszJgxnm0/+OCDnB4O4Ln8kWtpJK+5OXnyZM+206ZNs2aHDx+2Zg0aNPDs12tpqj/96U/WrEKFCp797tmzx5otX77cmr366que/QJ5TXCwvYxxLbnq1bZNmzbW7L777vPst1atWtYsPDw8oPFIUlJSkjX76quvrNnYsWM9+126dKlnjv/HmWYAAADAgaIZAAAAcKBoBgAAABwomgEAAAAHimYAAADAgaIZAAAAcGDJuQyULl3amnktJSNJL7/8sjWrWbNmwGMK1Pr16z3zF154wZotXrzYmqWkpAQ8JiA3BAUFWbMBAwZ4tu3cubM1O378uDW7/vrr3QMLwJdffumZx8XFWbOnn346p4cD5JoSJUpYs1tvvdWz7dChQ61ZpUqVrFloaKh7YAFw/b2eNGmSNZs/f741cy3HiczjTDMAAADgQNEMAAAAOFA0AwAAAA4UzQAAAIADRTMAAADgQNEMAAAAOFA0AwAAAA4+k8kF/Hw+38UeS44qVqyYNXv99dc920ZFRVmzqlWrBjqkbPFal3XixInWbPny5Z79nj59OuAxwS2vr495uc3rChUqWLN3333Xs229evUCPq7X/ZSdx/jw4cPWzGvd1YcffjjgYyL7mNc5q3jx4tZs2rRpnm3r1KljzbyeLy6mjRs3WrPY2FhrtmDBAs9+z5w5E+iQkAmZmdecaQYAAAAcKJoBAAAAB4pmAAAAwIGiGQAAAHCgaAYAAAAcKJoBAAAAhzy95Fz9+vU98yFDhlizW265xZqVL18+4DFlx6lTp6zZ5MmTPduOHTvWmp08eTLgMeHiYmmqS6ds2bKe+YMPPmjNhg0b5tk20CXnJk2a5Nnva6+9Zs1++uknz7bIPczr9CIjIz3zfv36BdTW9ff6mmuusWYlSpTwbOvFa3m3f/7zn55tx48fb82OHTsW8JhwcbHkHAAAAJADKJoBAAAAB4pmAAAAwIGiGQAAAHCgaAYAAAAcKJoBAAAAB4pmAAAAwCFPr9Pstdah5L1Oc3Zs377dmn344YeebZOSkqzZxIkTrVl8fLxzXLj8sJ4rcOVhXqf32GOPeeZe6zRnx86dO63Z6tWrPdumpKRYs2nTplmzhIQE98Bw2WGdZgAAACAHUDQDAAAADhTNAAAAgANFMwAAAOBA0QwAAAA4UDQDAAAADnl6yTngcsfSVMCVh3kNXHlYcg4AAADIARTNAAAAgANFMwAAAOBA0QwAAAA4UDQDAAAADhTNAAAAgANFMwAAAOBA0QwAAAA4UDQDAAAADhTNAAAAgANFMwAAAOBA0QwAAAA4UDQDAAAADhTNAAAAgANFMwAAAOBA0QwAAAA4UDQDAAAADhTNAAAAgANFMwAAAOBA0QwAAAA4UDQDAAAADj5jjMntQQAAAAB5GWeaAQAAAAeKZgAAAMCBohkAAABwoGgGAAAAHCiaAQAAAAeKZgAAAMCBohkAAABwoGgGAAAAHCiaAQAAAIf/BQZ+9DmR+Z8BAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 900x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixup loss: 1.5127\n",
      "Mixed prediction probs: [[1.3689329e-03 2.6107987e-04 3.3764855e-03 3.8774496e-01 5.8602295e-06\n",
      "  5.9345216e-01 1.7844657e-04 2.0511993e-03 1.1347534e-02 2.1333095e-04]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A visual demonstration of how two inputs can get mixed up:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# 1️) Load two MNIST samples\n",
    "# -------------------------\n",
    "transform = transforms.ToTensor()\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "x1, y1 = mnist[0]  # Example 1\n",
    "x2, y2 = mnist[1]  # Example 2\n",
    "\n",
    "# -------------------------\n",
    "# 2️) Mixup the two samples\n",
    "# -------------------------\n",
    "alpha = 0.4\n",
    "lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "mixed_x = lam * x1 + (1 - lam) * x2\n",
    "\n",
    "# -------------------------\n",
    "# 3️) Display side-by-side, bigger images\n",
    "# -------------------------\n",
    "def show_images(x1, x2, mixed_x, y1, y2, lam):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(9, 3))\n",
    "    axs[0].imshow(x1.squeeze().numpy(), cmap='gray')\n",
    "    axs[0].set_title(f'Original 1 (Label {y1})')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(x2.squeeze().numpy(), cmap='gray')\n",
    "    axs[1].set_title(f'Original 2 (Label {y2})')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(mixed_x.squeeze().numpy(), cmap='gray')\n",
    "    axs[2].set_title(f'Mixup\\n{lam:.2f}*{y1} + {1 - lam:.2f}*{y2}')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_images(x1, x2, mixed_x, y1, y2, lam)\n",
    "\n",
    "# -------------------------\n",
    "# 4️) Define a quick model\n",
    "# -------------------------\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------\n",
    "# 5️) Quick train on MNIST subset so model has some idea\n",
    "# -------------------------\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loader = DataLoader(mnist, batch_size=64, shuffle=True)\n",
    "model.train()\n",
    "for batch_idx, (data, target) in enumerate(loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx > 100:  # quick 100 batches for speed\n",
    "        break\n",
    "\n",
    "# -------------------------\n",
    "# 6️) Run predictions on originals + mixed\n",
    "# -------------------------\n",
    "model.eval()\n",
    "x1 = x1.unsqueeze(0).to(device)\n",
    "x2 = x2.unsqueeze(0).to(device)\n",
    "mixed_x = mixed_x.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred1 = model(x1)\n",
    "    pred2 = model(x2)\n",
    "    pred_mixed = model(mixed_x)\n",
    "\n",
    "# -------------------------\n",
    "# 7) Compute mixup loss\n",
    "# -------------------------\n",
    "y_a = torch.tensor([y1]).to(device)\n",
    "y_b = torch.tensor([y2]).to(device)\n",
    "\n",
    "loss_mixed = lam * criterion(pred_mixed, y_a) + (1 - lam) * criterion(pred_mixed, y_b)\n",
    "print(f\"Mixup loss: {loss_mixed.item():.4f}\")\n",
    "\n",
    "# Optionally, view predicted probabilities\n",
    "probs = F.softmax(pred_mixed, dim=1).cpu().numpy()\n",
    "print(f\"Mixed prediction probs: {probs}\")\n",
    "\n",
    "# -------------------------\n",
    "# 8) Visualize change in predicted probabilities by combining two samples\n",
    "# -------------------------\n",
    "\n",
    "# Compute softmax probabilities\n",
    "probs1 = F.softmax(pred1, dim=1).cpu().numpy().flatten()\n",
    "probs2 = F.softmax(pred2, dim=1).cpu().numpy().flatten()\n",
    "probs_mixed = F.softmax(pred_mixed, dim=1).cpu().numpy().flatten()\n",
    "\n",
    "# Plot bar charts\n",
    "def plot_probabilities(probs1, probs2, probs_mixed):\n",
    "    classes = np.arange(10)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
    "\n",
    "    axs[0].bar(classes, probs1)\n",
    "    axs[0].set_title('Prediction on Original 1')\n",
    "    axs[0].set_xticks(classes)\n",
    "    axs[0].set_ylim(0, 1)\n",
    "\n",
    "    axs[1].bar(classes, probs2)\n",
    "    axs[1].set_title('Prediction on Original 2')\n",
    "    axs[1].set_xticks(classes)\n",
    "\n",
    "    axs[2].bar(classes, probs_mixed)\n",
    "    axs[2].set_title('Prediction on Mixup')\n",
    "    axs[2].set_xticks(classes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_probabilities(probs1, probs2, probs_mixed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abcb35e",
   "metadata": {},
   "source": [
    "### CutMix Augmentation\n",
    "\n",
    "If mixup augments data by combining two images and their criterion holistically, then CutMix augmentation combines data by cutting out and repatching portions of an image into another image.\n",
    "\n",
    "- This is accomplished in a very similar fashion to the idea of applying a mask in Drop Out layers. However, instead of just neutralizing values by zeroing them out, we use two inverse masks on two samples to effective cut one portion of an image into the same region of another image.\n",
    "\n",
    "To understand how this is accomplished lets first tackle the idea of \"masking\" more generally.\n",
    "\n",
    "Consider the mask: \n",
    "\n",
    "$$ A =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "If we performed element wise multiplication between this mask and an image, only the top left corner of the image would be preserved.\n",
    "\n",
    "- **How could we accomplish the opposite? (preserve everything except the top left of the 5 by 5 image)**\n",
    "\n",
    "- Well we could simply calculate $1 - A$ where $1$ expands to a 5 by 5 matrix filled with 1s.\n",
    "\n",
    "$$ 1 - A =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 & 1 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "-\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & 1 & 1 \\\\\n",
    "0 & 0 & 0 & 1 & 1 \\\\\n",
    "0 & 0 & 0 & 1 & 1 \\\\\n",
    "1 & 1 & 1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 & 1 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We could extract the top left patch from some image $x_1$ and the residual (everything except the top left patch) from some image $x_2$ and combine the two images as follows:\n",
    "\n",
    "$$x_{\\text{combined}} = A \\odot x_1 + (1 - A) \\odot x_2$$\n",
    "\n",
    "- $\\odot$ is the element-wise multiplication operator.\n",
    "\n",
    "We could apply similar logic to combine the classification labels of the two respective labels (i.e. their final )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
